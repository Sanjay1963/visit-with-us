name: visit-with-us-mlops-pipeline

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

env:
  PYTHON_VERSION: "3.10"
  MODEL_DIR: artifacts/model
  DATA_DIR: artifacts/data

jobs:
  mlops-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install pandas scikit-learn joblib datasets huggingface_hub

      - name: Data ingestion check
        run: |
          test -f tourism.csv
          echo "Found tourism.csv"

      - name: Data preparation (clean + split)
        run: |
          mkdir -p $DATA_DIR
          python - << 'PY'
          import pandas as pd
          from sklearn.model_selection import train_test_split

          df = pd.read_csv('tourism.csv')
          if 'CustomerID' in df.columns:
              df = df.drop(columns=['CustomerID'])
          df = df.fillna(method='ffill').fillna(method='bfill')

          train_df, test_df = train_test_split(
              df, test_size=0.2, random_state=42, stratify=df['ProdTaken']
          )
          train_df.to_csv('artifacts/data/train.csv', index=False)
          test_df.to_csv('artifacts/data/test.csv', index=False)
          print('Prepared:', train_df.shape, test_df.shape)
          PY

      - name: Model training
        run: |
          mkdir -p $MODEL_DIR
          python - << 'PY'
          import pandas as pd
          import joblib
          from sklearn.ensemble import RandomForestClassifier
          from sklearn.preprocessing import LabelEncoder

          train_df = pd.read_csv('artifacts/data/train.csv')
          encoders = {}
          for col in train_df.select_dtypes(include='object').columns:
              le = LabelEncoder()
              train_df[col] = le.fit_transform(train_df[col].astype(str))
              encoders[col] = le

          X_train = train_df.drop('ProdTaken', axis=1)
          y_train = train_df['ProdTaken']

          model = RandomForestClassifier(
              n_estimators=200, max_depth=10, min_samples_split=2, random_state=42
          )
          model.fit(X_train, y_train)

          joblib.dump(model, 'artifacts/model/best_model.pkl')
          joblib.dump(encoders, 'artifacts/model/encoders.pkl')
          print('Model training completed')
          PY

      - name: Model evaluation
        run: |
          python - << 'PY'
          import pandas as pd
          import joblib
          from sklearn.metrics import accuracy_score, classification_report

          test_df = pd.read_csv('artifacts/data/test.csv')
          model = joblib.load('artifacts/model/best_model.pkl')
          encoders = joblib.load('artifacts/model/encoders.pkl')

          for col, le in encoders.items():
              if col in test_df.columns:
                  test_df[col] = test_df[col].astype(str).map(
                      lambda x: le.transform([x])[0] if x in le.classes_ else 0
                  )

          X_test = test_df.drop('ProdTaken', axis=1)
          y_test = test_df['ProdTaken']
          y_pred = model.predict(X_test)

          acc = accuracy_score(y_test, y_pred)
          print(f'Accuracy: {acc:.4f}')
          print(classification_report(y_test, y_pred))

          if acc < 0.75:
              raise SystemExit('Model accuracy below expected threshold (0.75)')
          PY

      - name: Register model to Hugging Face Hub (optional)
        if: ${{ github.event_name == 'push' && github.ref == 'refs/heads/main' && secrets.hf_token != '' && vars.HF_MODEL_REPO != '' }}
        env:
          hf_token: ${{ secrets.hf_token }}
          HF_MODEL_REPO: ${{ vars.HF_MODEL_REPO }}
        run: |
          python - << 'PY'
          import os
          from huggingface_hub import HfApi

          api = HfApi(token=os.environ['hf_token'])
          repo_id = os.environ['HF_MODEL_REPO']

          api.create_repo(repo_id=repo_id, repo_type='model', exist_ok=True)
          api.upload_file(path_or_fileobj='artifacts/model/best_model.pkl', path_in_repo='best_model.pkl', repo_id=repo_id, repo_type='model')
          api.upload_file(path_or_fileobj='artifacts/model/encoders.pkl', path_in_repo='encoders.pkl', repo_id=repo_id, repo_type='model')
          print('Model registered to Hugging Face Hub')
          PY

      - name: Deployment artifact check
        run: |
          test -f Dockerfile
          test -f app.py
          test -f requirements.txt
          echo "Deployment files validated"

      - name: Upload pipeline artifacts
        uses: actions/upload-artifact@v4
        with:
          name: visit-with-us-artifacts
          path: |
            artifacts/data/train.csv
            artifacts/data/test.csv
            artifacts/model/best_model.pkl
            artifacts/model/encoders.pkl
